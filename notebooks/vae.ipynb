{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
<<<<<<< HEAD
   "name": "python_defaultSpec_1599184612257",
   "display_name": "Python 3.7.7 64-bit ('pytorch': conda)"
=======
   "name": "python3",
   "display_name": "Python 3"
>>>>>>> nflows
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "env: WANDB_MODE=&quot;dryrun&quot;\n"
    }
   ],
   "source": [
    "%env WANDB_MODE=\"dryrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "import os\n",
    "os.chdir('..')\n",
    "\n",
=======
>>>>>>> nflows
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mcmc import LangevinMCMC\n",
    "from torch.distributions import Normal\n",
    "import torch"
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = Normal(loc=torch.tensor([3.0, 6.0]), scale=torch.tensor([1.0, 5.0]))\n",
    "x = torch.randn(32, 2)"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.base import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from src.experiments import Fusion_MVAE_Experiment, MVAE_Tester\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc  = LangevinMCMC(normal_dist, eps=0.01)"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"configs/mnist_svhn/fusion.yaml\"\n",
    "\n",
    "with open(config, \"r\") as file:\n",
    "    try:\n",
    "        hparams = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = mcmc.simulate(x, n_steps=1000, create_graph=True)"
=======
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using downloaded and verified file: data/train_32x32.mat\nUsing downloaded and verified file: data/test_32x32.mat\n"
    }
   ],
   "source": [
    "exp = Fusion_MVAE_Experiment(hparams)"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
=======
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
>>>>>>> nflows
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
<<<<<<< HEAD
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "x1.requires_grad"
=======
      "text/plain": "&lt;IPython.core.display.HTML object&gt;",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/lemonwaffle/vae-expts\" target=\"_blank\">https://app.wandb.ai/lemonwaffle/vae-expts</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/lemonwaffle/vae-expts/runs/vaevae_concat_0\" target=\"_blank\">https://app.wandb.ai/lemonwaffle/vae-expts/runs/vaevae_concat_0</a><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.4 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
    }
   ],
   "source": [
    "# Init logger\n",
    "project_name = \"vae-expts\"\n",
    "wandb_logger = WandbLogger(\n",
    "    name=hparams[\"name\"], project=project_name, id=hparams[\"name\"],  # For resuming\n",
    ")\n",
    "wandb_logger.log_hyperparams(hparams)"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p = mcmc.dist.log_prob(x1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bad987a619bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/vi-lab/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    190\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    191\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "grad = torch.autograd.grad(log_p.detach(), x1, create_graph=True)[0]"
=======
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        fast_dev_run=True,\n",
    "        deterministic=True,\n",
    "        benchmark=True,\n",
    "        gpus=1,\n",
    "        logger=wandb_logger,\n",
    "        weights_summary=\"top\",\n",
    "        max_epochs=1,\n",
    "        val_check_interval=0.25,\n",
    "        # limit_val_batches=0.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.4 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\n  | Name  | Type          | Params\n----------------------------------------\n0 | model | MultimodalVAE | 1 M   \n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style=&#39;info&#39;, description=&#39;Training&#39;, layout=Layout(flex=&#39;2&#39;), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39ec51e2b6be4e04b1b0c2043cbadc48"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style=&#39;info&#39;, description=&#39;Validating&#39;, layout=Layout(flex=&#39;2&#39;), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "633ff3c0f53243cebb1cdb90675650d9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Saving latest checkpoint..\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "trainer.fit(exp)"
>>>>>>> nflows
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}